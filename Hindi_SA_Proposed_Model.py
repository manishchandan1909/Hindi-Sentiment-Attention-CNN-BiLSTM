# -*- coding: utf-8 -*-
"""Hindi Sentiment Analysis using an attention-augmented CNN Bi-LSTM framework with TF-IDF-weighted Word2Vec embeddings.ipynb

Automatically generated by Colab.
"""

# === Install required packages (Colab) ===
!pip install gensim

!pip install indic-nlp-library
# download the resource
!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git
# download the repo
!git clone https://github.com/anoopkunchukuttan/indic_nlp_library.git


import sys
from indicnlp import common

# The path to the local git repo for Indic NLP library
INDIC_NLP_LIB_HOME=r"indic_nlp_library"

# The path to the local git repo for Indic NLP Resources
INDIC_NLP_RESOURCES=r"indic_nlp_resources"

# Add library to Python path
sys.path.append(r'{}\src'.format(INDIC_NLP_LIB_HOME))

# Set environment variable for resources folder
common.set_resources_path(INDIC_NLP_RESOURCES)

from google.colab import drive
# Mount Google Drive
drive.mount('/content/gdrive')

# ============================================
# ENHANCED COMPUTATIONAL METRICS TRACKING SETUP
# ============================================
import time
import psutil
import os
import tensorflow as tf # Import tensorflow
from tensorflow.python.profiler import profiler_v2 as profiler

class ComputationalMetrics:
    """Track comprehensive computational metrics for model training and inference"""

    def __init__(self):
        self.training_start_time = None
        self.training_end_time = None
        self.inference_times = []
        self.memory_snapshots = [] # For CPU memory
        self.gpu_memory_allocated_snapshots = [] # For TF GPU allocated memory
        self.flops_count = None
        self.process = psutil.Process(os.getpid())
        self.total_params = 0
        self.trainable_params = 0
        self.test_accuracy = None

        # Enable memory growth for TensorFlow to prevent OOM errors and allow proper tracking
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            try:
                for gpu in gpus:
                    tf.config.experimental.set_memory_growth(gpu, True)
                print("[METRICS] TensorFlow GPU memory growth enabled.")
            except RuntimeError as e:
                print(f"[METRICS] Error setting TF memory growth: {e}")

    def start_training(self):
        """Start training timer and record initial memory state"""
        self.training_start_time = time.time()
        self.record_memory_usage()
        print(f"[METRICS] Training started at {time.strftime('%Y-%m-%d %H:%M:%S')}")

    def end_training(self):
        """End training timer and record final memory state"""
        self.training_end_time = time.time()
        self.record_memory_usage()
        print(f"[METRICS] Training ended at {time.strftime('%Y-%m-%d %H:%M:%S')}")

    def get_training_time(self):
        """Get total training time in seconds"""
        if self.training_start_time and self.training_end_time:
            return self.training_end_time - self.training_start_time
        return None

    def get_training_time_minutes(self):
        """Get total training time in minutes"""
        training_time = self.get_training_time()
        return training_time / 60 if training_time else None

    def record_inference_time(self, inference_time):
        """Record individual inference time"""
        self.inference_times.append(inference_time)

    def get_average_inference_time(self):
        """Calculate average inference time in seconds"""
        if self.inference_times:
            return sum(self.inference_times) / len(self.inference_times)
        return None

    def get_average_inference_time_ms(self):
        """Calculate average inference time in milliseconds"""
        avg_time = self.get_average_inference_time()
        return avg_time * 1000 if avg_time else None

    def record_memory_usage(self):
        """Record both CPU and GPU memory usage"""
        # CPU Memory (RAM)
        memory_info = self.process.memory_info()
        cpu_memory_gb = memory_info.rss / (1024 ** 3)
        self.memory_snapshots.append({
            'timestamp': time.time(),
            'cpu_memory_gb': cpu_memory_gb,
            'cpu_memory_mb': memory_info.rss / (1024 ** 2)
        })

        # GPU Memory (if available for TensorFlow)
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            try:
                # Assuming 'GPU:0' is the primary GPU
                gpu_info = tf.config.experimental.get_memory_info('GPU:0')
                gpu_allocated_gb = gpu_info['current'] / (1024 ** 3) # 'current' is current allocated bytes
                self.gpu_memory_allocated_snapshots.append(gpu_allocated_gb)
            except Exception as e:
                print(f"[METRICS] Could not get TF GPU memory info: {e}")
                self.gpu_memory_allocated_snapshots.append(0.0) # Append 0 if error, or None

    def get_peak_cpu_memory_usage(self):
        """Get peak CPU memory usage in GB"""
        if self.memory_snapshots:
            return max(snapshot['cpu_memory_gb'] for snapshot in self.memory_snapshots)
        return None

    def get_peak_gpu_memory_usage(self):
        """Get peak TensorFlow GPU allocated memory in GB"""
        if self.gpu_memory_allocated_snapshots:
            return max(self.gpu_memory_allocated_snapshots)
        return None

    def get_max_gpu_memory_allocated(self):
        """For TensorFlow, this is the same as peak_gpu_memory_usage if tracking correctly"""
        # However, TF also reports a 'peak' value which is peak for the current session/process
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            try:
                gpu_info = tf.config.experimental.get_memory_info('GPU:0')
                return gpu_info['peak'] / (1024 ** 3)
            except Exception as e:
                print(f"[METRICS] Could not get TF reported peak GPU memory info: {e}")
        return self.get_peak_gpu_memory_usage() # Fallback to our tracked peak

    def get_current_memory_usage(self):
        """Get current memory usage"""
        memory_info = self.process.memory_info()
        cpu_memory_gb = memory_info.rss / (1024 ** 3)

        result = {
            'cpu_memory_gb': cpu_memory_gb,
            'cpu_memory_mb': memory_info.rss / (1024 ** 2)
        }

        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            try:
                gpu_info = tf.config.experimental.get_memory_info('GPU:0')
                result['gpu_allocated_gb'] = gpu_info['current'] / (1024 ** 3)
                result['gpu_peak_gb_tf_reported'] = gpu_info['peak'] / (1024 ** 3)
            except Exception as e:
                print(f"[METRICS] Could not get current TF GPU memory info: {e}")

        return result

    def set_model_params(self, total_params, trainable_params):
        """Set model parameter counts"""
        self.total_params = total_params
        self.trainable_params = trainable_params

    def set_flops(self, flops_count):
        """Set FLOPs count"""
        self.flops_count = flops_count

    def set_test_accuracy(self, accuracy):
        """Set test accuracy"""
        self.test_accuracy = accuracy

    def print_summary(self):
        """Print comprehensive metrics summary"""
        print("\n" + "="*80)
        print("COMPUTATIONAL METRICS SUMMARY")
        print("="*80)

        # Model Architecture
        print("\n--- MODEL ARCHITECTURE ---")
        if self.total_params:
            print(f"Total Parameters: {self.total_params:,}")
        if self.trainable_params:
            print(f"Trainable Parameters: {self.trainable_params:,}")

        # Training Time
        if self.get_training_time():
            print("\n--- TRAINING TIME ---")
            print(f"Training Time (seconds): {self.get_training_time():.2f} s")
            print(f"Training Time (minutes): {self.get_training_time_minutes():.2f} min")

        # Inference Latency
        if self.get_average_inference_time():
            print("\n--- INFERENCE LATENCY ---")
            print(f"Average Inference Time (single): {self.get_average_inference_time_ms():.4f} ms")

        # CPU Memory
        if self.get_peak_cpu_memory_usage():
            print("\n--- CPU MEMORY USAGE ---")
            print(f"Peak CPU Memory Usage: {self.get_peak_cpu_memory_usage():.4f} GB")
            if len(self.memory_snapshots) >= 2:
                initial_mem = self.memory_snapshots[0]['cpu_memory_gb']
                peak_mem = self.get_peak_cpu_memory_usage()
                print(f"Memory Growth: {peak_mem - initial_mem:.4f} GB")

        # GPU Memory
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            print("\n--- GPU MEMORY USAGE (TensorFlow) ---")
            peak_gpu_alloc = self.get_peak_gpu_memory_usage()
            tf_reported_peak = self.get_max_gpu_memory_allocated()
            if peak_gpu_alloc is not None:
                print(f"Peak GPU Allocated (tracked): {peak_gpu_alloc:.4f} GB")
            if tf_reported_peak is not None:
                print(f"Peak GPU Reported by TF: {tf_reported_peak:.4f} GB")
            if peak_gpu_alloc is None and tf_reported_peak is None:
                print("No GPU memory allocation tracked.")

        # FLOPs
        if self.flops_count:
            print("\n--- COMPUTATIONAL COMPLEXITY ---")
            print(f"FLOPs per Sample: {self.flops_count:,}")
            print(f"FLOPs (GFLOPs): {self.flops_count / 1e9:.4f} GFLOPs")

        # Test Accuracy
        if self.test_accuracy is not None:
            print("\n--- MODEL PERFORMANCE ---")
            print(f"Test Accuracy: {self.test_accuracy:.4f} ({self.test_accuracy*100:.2f}%)")

        print("="*80 + "\n")

    def print_paper_table(self, batch_inference_time=None, batch_size=None):
        """Print formatted table for research paper"""
        print("\n" + "="*80)
        print("COMPREHENSIVE METRICS TABLE FOR RESEARCH PAPER")
        print("="*80)
        print(f"{'Metric':<40} {'Value':<40}")
        print("-"*80)

        # Model Architecture
        if self.total_params:
            print(f"{'Total Parameters':<40} {self.total_params:,}")
        if self.trainable_params:
            print(f"{'Trainable Parameters':<40} {self.trainable_params:,}")

        # Training Time
        if self.get_training_time():
            print(f"{'Training Time (seconds)':<40} {self.get_training_time():.2f} s")
            print(f"{'Training Time (minutes)':<40} {self.get_training_time_minutes():.2f} min")

        # Inference Latency
        if self.get_average_inference_time_ms():
            print(f"{'Inference Latency - Single (ms)':<40} {self.get_average_inference_time_ms():.4f} ms")

        if batch_inference_time and batch_size:
            batch_avg_ms = (batch_inference_time / batch_size) * 1000
            print(f"{'Inference Latency - Batch (ms)':<40} {batch_avg_ms:.4f} ms")

        # FLOPs
        if self.flops_count:
            print(f"{'FLOPs per Sample':<40} {self.flops_count:,}")
            print(f"{'FLOPs (GFLOPs)':<40} {self.flops_count / 1e9:.4f}")

        # Memory Usage
        if self.get_peak_cpu_memory_usage():
            print(f"{'Peak CPU Memory Usage (GB)':<40} {self.get_peak_cpu_memory_usage():.4f} GB")

        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            peak_gpu_alloc = self.get_peak_gpu_memory_usage()
            tf_reported_peak = self.get_max_gpu_memory_allocated()
            if peak_gpu_alloc is not None:
                print(f"{'Peak GPU Memory Allocated (tracked) (GB)':<40} {peak_gpu_alloc:.4f} GB")
            if tf_reported_peak is not None:
                print(f"{'Peak GPU Reported by TF (GB)':<40} {tf_reported_peak:.4f} GB")

        # Test Accuracy
        if self.test_accuracy is not None:
            print(f"{'Test Accuracy':<40} {self.test_accuracy:.4f}")

        print("="*80 + "\n")

    def export_to_dict(self):
        """Export all metrics to a dictionary"""
        metrics_dict = {
            'model_architecture': {
                'total_parameters': int(self.total_params) if self.total_params is not None else None,
                'trainable_parameters': int(self.trainable_params) if self.trainable_params is not None else None
            },
            'training': {
                'training_time_seconds': float(self.get_training_time()) if self.get_training_time() is not None else None,
                'training_time_minutes': float(self.get_training_time_minutes()) if self.get_training_time_minutes() is not None else None
            },
            'inference': {
                'average_inference_time_ms': float(self.get_average_inference_time_ms()) if self.get_average_inference_time_ms() is not None else None,
                'average_inference_time_s': float(self.get_average_inference_time()) if self.get_average_inference_time() is not None else None
            },
            'computational_complexity': {
                'flops_per_sample': int(self.flops_count) if self.flops_count is not None else None,
                'gflops': float(self.flops_count / 1e9) if self.flops_count is not None else None
            },
            'memory_usage': {
                'peak_cpu_memory_gb': float(self.get_peak_cpu_memory_usage()) if self.get_peak_cpu_memory_usage() is not None else None,
                'peak_gpu_memory_allocated_gb': float(self.get_peak_gpu_memory_usage()) if self.get_peak_gpu_memory_usage() is not None else None,
            },
            'performance': {
                'test_accuracy': float(self.test_accuracy) if self.test_accuracy is not None else None
            }
        }
        # Add TF reported peak if available
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            tf_reported_peak = self.get_max_gpu_memory_allocated()
            if tf_reported_peak is not None:
                metrics_dict['memory_usage']['max_gpu_memory_reported_by_tf_gb'] = float(tf_reported_peak)
        return metrics_dict

# Initialize metrics tracker
metrics = ComputationalMetrics()
print("[METRICS] Enhanced computational metrics tracker initialized")
metrics.record_memory_usage()


# ============================================
# IMPORT LIBRARIES
# ============================================
import re
import string
import pandas as pd
import numpy as np
# import torch # Removed torch import
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

nltk.download('punkt')
nltk.download('stopwords')

# ============================================
# DATA LOADING AND PREPROCESSING
# ============================================

# Record memory usage at start
metrics.record_memory_usage()

# Parameterized file path to improve flexibility
dataset_path = 'combined_dataset.csv'

# Load dataset
df = pd.read_csv(dataset_path)

# Display the loaded DataFrame and basic information
print("First few rows of the dataset:")
print(df.head())

# Handling missing values
print("\nHandling missing values...")
df = df.dropna()

# Checking and displaying class distribution
print("\nClass distribution:")
polarity_counts = df['polarity'].value_counts()
print(polarity_counts)

print("\nNull values check:")
print(df.isnull().sum())

# ============================================
# VISUALIZE CLASS DISTRIBUTION
# ============================================
polarity_counts = df['polarity'].value_counts()

# Create a bar plot with different colors for each polarity
plt.figure(figsize=(8, 6))
plt.bar(polarity_counts.index, polarity_counts.values, color=['red', 'green'])
plt.xlabel('Polarity')
plt.ylabel('Count')
plt.title('Polarity Distribution')
plt.show()

# ============================================
# INITIALIZE INDIC NLP TOOLS
# ============================================
from indicnlp.normalize.indic_normalize import IndicNormalizerFactory
normalizer_factory = IndicNormalizerFactory()
normalizer = normalizer_factory.get_normalizer('hi')

# ============================================
# TEXT PREPROCESSING
# ============================================

def processText(text):
    # Normalize text
    text = normalizer.normalize(text)

    # Convert to lowercase
    text = text.lower()

    # Remove URLs
    text = re.sub(r'((www\.[^\s]+)|(https?://[^\s]+))', '', text)

    # Remove mentions
    text = re.sub(r'@[^\s]+', '', text)

    # Replace hashtags with the word following '#'
    text = re.sub(r'#([^\s]+)', r'\1', text)

    # Remove special characters but keep Hindi characters and spaces
    text = re.sub(r'[^ऀ-ॿ\s]', '', text)

    # Remove punctuation characters including brackets, full stops, commas, etc.
    text = re.sub(r'[.,!?:;\-\'\"\/\(\)\[\]\{\}]', '', text)

    # Remove extra spaces
    text = re.sub(r'\s+', ' ', text).strip()

    # Strip leading and trailing quotes
    text = text.strip('\'\"')

    return text

# Apply the function to your dataframe column
print("\nPreprocessing text...")
df['text'] = df['text'].apply(processText)

# Remove hindi full stop special character
def remove_hindi_full_stop(text):
    """Removes the Hindi full stop (।) from the given text."""
    return text.replace('।', '')

# Apply the function to the 'text' column
df['text'] = df['text'].apply(remove_hindi_full_stop)

print("\nPreprocessed data sample:")
print(df.head())

# ============================================
# LABEL ENCODING
# ============================================
from sklearn.preprocessing import LabelEncoder

# Initialize LabelEncoder
label_encoder = LabelEncoder()

# Perform label encoding on the 'sentiment' column
df['polarity'] = label_encoder.fit_transform(df['polarity'])

# Get the class labels and their corresponding encoded values
class_labels = label_encoder.classes_
encoded_labels = label_encoder.transform(class_labels)

# Print the polarity and their encoded labels
for label, encoded_value in zip(class_labels, encoded_labels):
    print(f"Polarity: {label}, Encoded Label: {encoded_value}")

print(df)

# ============================================
# TOKENIZATION
# ============================================
from indicnlp.tokenize import indic_tokenize

def tokenization(indic_string):
    tokens = []
    for t in indic_tokenize.trivial_tokenize(indic_string):
        tokens.append(t)
    return tokens

df['tokenized_text'] = df['text'].apply(lambda x: tokenization(x))

print(df)

# ============================================
# VOCABULARY CREATION
# ============================================
import re

def create_vocabulary(df):
    # Initialize the vocabulary dictionary
    vocabulary = {}
    index = 0

    # Add special tokens for digits and unknown words at the beginning
    vocabulary['digit'] = index
    index += 1
    vocabulary['unknown'] = index
    index += 1

    # Process each text in the 'tokenized_text' column of the DataFrame
    for text in df['tokenized_text']:
        for word in text:
            word = word.lower()  # Convert word to lowercase for case insensitivity

            # Check if the word is a digit
            if re.match(r'^\d+$', word):
                continue  # Skip adding digits since we have a "digit" token

            # Add unique words to the dictionary
            if word not in vocabulary:
                vocabulary[word] = index
                index += 1

    return vocabulary

# Create vocabulary
vocabulary = create_vocabulary(df)
print(f"Vocabulary size: {len(vocabulary)}")

# ============================================
# SAVE VOCABULARY
# ============================================
import pickle

# Save the vocabulary to a file
with open('vocabulary.pkl', 'wb') as f:
    pickle.dump(vocabulary, f)

# ============================================
# WORD EMBEDDINGS (Word2Vec + TF-IDF)
# ============================================
from gensim.models import Word2Vec
from sklearn.feature_extraction.text import TfidfVectorizer

# Step 1: Load vocabulary
with open('vocabulary.pkl', 'rb') as f:
    vocabulary = pickle.load(f)

# Assuming 'tokenized_text' column contains tokenized text
sentences = df['tokenized_text'].tolist()

# Step 2: Train Word2Vec model (CBoW with 200 dimensions)
embedding_dim = 200
model_word2vec = Word2Vec(sentences, vector_size=embedding_dim, window=5, min_count=1, sg=0, workers=4)  # sg=0 for CBoW

# Save the trained Word2Vec model
model_word2vec.save("word2vec_cbow_200d.model")

# Step 3: Compute TF-IDF weights
sentences_as_text = [' '.join(sentence) for sentence in sentences]

# Initialize TfidfVectorizer
tfidf = TfidfVectorizer(vocabulary=vocabulary, tokenizer=lambda x: x, preprocessor=lambda x: x, token_pattern=None)
tfidf_matrix = tfidf.fit_transform(sentences_as_text)

# Extract the TF-IDF weights for words
tfidf_weights = dict(zip(tfidf.get_feature_names_out(), tfidf.idf_))

# Step 4: Create an embedding matrix by combining Word2Vec with TF-IDF
embedding_matrix = np.zeros((len(vocabulary) + 1, embedding_dim))

for word, idx in vocabulary.items():
    if word in model_word2vec.wv:
        embedding_vector = model_word2vec.wv[word]
    else:
        embedding_vector = np.random.randn(embedding_dim)

    # Apply TF-IDF weighting if available
    tfidf_weight = tfidf_weights.get(word, 1.0)
    embedding_matrix[idx] = embedding_vector * tfidf_weight

# Save the embedding matrix for future use
np.save("embedding_matrix.npy", embedding_matrix)

print("Word embeddings created successfully!")

# Record memory usage after preprocessing
metrics.record_memory_usage()

# ============================================
# MODEL BUILDING WITH CHECKPOINT MANAGEMENT
# ============================================
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPooling1D, Concatenate, Dense, Dropout, Bidirectional, LSTM
from tensorflow.keras.layers import Attention, GaussianNoise, Lambda
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
from gensim.models import Word2Vec
import pickle
from tensorflow.keras.layers import GaussianDropout
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

# Step 1: Load vocabulary
with open('vocabulary.pkl', 'rb') as f:
    vocabulary = pickle.load(f)

# Function to convert text data to numerical sequences
def text_to_sequences(texts, vocabulary):
    sequences = []
    for text in texts:
        sequence = []
        for word in text:
            if word in vocabulary:
                sequence.append(vocabulary[word])
            elif word.isdigit():
                sequence.append(vocabulary['digit'])
            else:
                sequence.append(vocabulary['unknown'])
        sequences.append(sequence)
    return sequences

# Convert text to sequences
X = text_to_sequences(df['tokenized_text'], vocabulary)
num_classes = 2
y = to_categorical(df['polarity'], num_classes=num_classes)

# Step 2: Splitting the data
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Step 3: Pad sequences
max_length = max(len(seq) for seq in X_train)
X_train_padded = pad_sequences(X_train, maxlen=max_length, padding='post')
X_val_padded = pad_sequences(X_val, maxlen=max_length, padding='post')
X_test_padded = pad_sequences(X_test, maxlen=max_length, padding='post')

# Step 4: Load Word2Vec model
model_word2vec = Word2Vec.load("word2vec_cbow_200d.model")

# Define embedding dimensions
embedding_dim = 200

# Step 5: Create embedding matrix
embedding_matrix = np.zeros((len(vocabulary) + 1, embedding_dim))
for word, i in vocabulary.items():
    if word in model_word2vec.wv:
        embedding_matrix[i] = model_word2vec.wv[word]

print("Shape of X_train_padded:", X_train_padded.shape)
print("Shape of X_test_padded:", X_test_padded.shape)

# Define scaled dot-product attention function
def scaled_dot_product_attention(queries, keys, values):
    """
    Scaled Dot-Product Attention with Softmax for optimizing attention weights.
    """
    dk = tf.cast(tf.shape(keys)[-1], tf.float32)
    scores = tf.matmul(queries, keys, transpose_b=True) / tf.math.sqrt(dk)
    attention_weights = tf.nn.softmax(scores, axis=-1)
    output = tf.matmul(attention_weights, values)
    return output

# Define output shape function for Lambda layer
def attention_output_shape(input_shape):
    """Return the output shape of the attention layer"""
    # input_shape should be (batch_size, sequence_length, embedding_dim)
    # The attention mechanism returns an output of the same shape as the values (last input to matmul)
    return input_shape

# Define the callable for the Lambda layer that wraps scaled_dot_product_attention
def apply_scaled_attention_to_lambda(inputs):
    # The Lambda layer's function receives one argument, which is the output of the previous layer (concat)
    # So we unpack it to queries, keys, values as needed by scaled_dot_product_attention
    return scaled_dot_product_attention(inputs, inputs, inputs)

# ============================================
# MODEL ARCHITECTURE
# ============================================

# Input Layer
input_layer = Input(shape=(max_length,))
gaussian_noise = GaussianNoise(0.5)(input_layer)

# Embedding Layer
embedding_layer = Embedding(input_dim=len(vocabulary) + 1,
                            output_dim=embedding_dim,
                            weights=[embedding_matrix],
                            input_length=max_length,
                            trainable=True)(gaussian_noise)

# Convolutional Layers with different filter sizes
conv_1 = Conv1D(filters=400, kernel_size=3, activation='relu', padding='same')(embedding_layer)
conv_2 = Conv1D(filters=250, kernel_size=3, activation='relu', padding='same')(embedding_layer)
conv_3 = Conv1D(filters=125, kernel_size=4, activation='relu', padding='same')(embedding_layer)

# MaxPooling Layers
pool_1 = MaxPooling1D(pool_size=2)(conv_1)
pool_2 = MaxPooling1D(pool_size=2)(conv_2)
pool_3 = MaxPooling1D(pool_size=2)(conv_3)

# Concatenation Layer
concat = Concatenate()([pool_1, pool_2, pool_3])

# Scaled Dot-Product Attention Layer with explicit output shape
attention_output = Lambda(
    apply_scaled_attention_to_lambda,
    output_shape=attention_output_shape
)(concat)

# BiLSTM Layer
bilstm = Bidirectional(LSTM(160, return_sequences=False, kernel_regularizer=l2(7.7306e-05)))(attention_output)

# Dense Layer
dense = Dense(160, activation='relu', kernel_regularizer=l2(7.7306e-05))(bilstm)

# Gaussian Dropout
dropout = GaussianDropout(0.2)(dense)

# Output Layer
output_layer = Dense(num_classes, activation='softmax')(dropout)

# Create Model
model = Model(inputs=input_layer, outputs=output_layer)

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.00020567),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Model Summary
model.summary()

# Count total and trainable parameters
total_params = model.count_params()
trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])

print(f"\nTotal Parameters: {total_params:,}")
print(f"Trainable Parameters: {trainable_params:,}")

# Store model parameters in metrics
metrics.set_model_params(total_params, trainable_params)

# ============================================
# FLOPS CALCULATION
# ============================================

def calculate_flops(model, batch_size=1, input_shape=None):
    """
    Estimate FLOPs for the model using compute_output_shape
    """
    flops = 0

    # Build the model if not already built
    if not model.built:
        if input_shape is None:
            input_shape = (batch_size, max_length)
        model.build(input_shape)

    print("\nDetailed FLOPs Calculation:")
    print("-"*80)

    # Get all layers recursively (including nested layers)
    def get_all_layers(model):
        layers = []
        for layer in model.layers:
            layers.append(layer)
            if hasattr(layer, 'layers'):
                layers.extend(get_all_layers(layer))
        return layers

    all_layers = get_all_layers(model)

    for layer in all_layers:
        layer_flops = 0
        try:
            if isinstance(layer, tf.keras.layers.Conv1D):
                # FLOPs for Conv1D: 2 * input_channels * output_channels * kernel_size * output_length
                kernel_size = layer.kernel_size[0]
                input_shape = layer.input_shape

                # Handle both single and batch inputs
                if isinstance(input_shape, list):
                    input_shape = input_shape[0]

                input_channels = input_shape[-1] if input_shape[-1] is not None else 200
                output_channels = layer.filters
                output_length = input_shape[1] if len(input_shape) > 1 and input_shape[1] is not None else max_length

                layer_flops = 2 * input_channels * output_channels * kernel_size * output_length * batch_size
                flops += layer_flops
                print(f"Conv1D ({layer.name}): {layer_flops:,} FLOPs")
                print(f"  - Filters: {output_channels}, Kernel: {kernel_size}, Input channels: {input_channels}, Length: {output_length}")

            elif isinstance(layer, tf.keras.layers.Dense):
                # FLOPs for Dense: 2 * input_dim * output_dim
                input_shape = layer.input_shape

                # Handle both single and batch inputs
                if isinstance(input_shape, list):
                    input_shape = input_shape[0]

                input_dim = input_shape[-1] if input_shape[-1] is not None else 160
                output_dim = layer.units

                layer_flops = 2 * input_dim * output_dim * batch_size
                flops += layer_flops
                print(f"Dense ({layer.name}): {layer_flops:,} FLOPs")
                print(f"  - Input dim: {input_dim}, Output dim: {output_dim}")

            elif isinstance(layer, tf.keras.layers.LSTM):
                # FLOPs for LSTM: approximately 4 * (input_dim * hidden_dim + hidden_dim * hidden_dim) per timestep
                input_shape = layer.input_shape

                # Handle both single and batch inputs
                if isinstance(input_shape, list):
                    input_shape = input_shape[0]

                input_dim = input_shape[-1] if len(input_shape) > 2 and input_shape[-1] is not None else 775
                hidden_dim = layer.units
                seq_length = input_shape[1] if len(input_shape) > 2 and input_shape[1] is not None else max_length // 2

                layer_flops = 4 * (input_dim * hidden_dim + hidden_dim * hidden_dim) * seq_length * batch_size
                flops += layer_flops
                print(f"LSTM ({layer.name}): {layer_flops:,} FLOPs")
                print(f"  - Input dim: {input_dim}, Hidden dim: {hidden_dim}, Seq length: {seq_length}")

            elif isinstance(layer, tf.keras.layers.Bidirectional):
                # For Bidirectional LSTM, multiply by 2
                if hasattr(layer, 'forward_layer'):
                    lstm_layer = layer.forward_layer
                    input_shape = layer.input_shape

                    # Handle both single and batch inputs
                    if isinstance(input_shape, list):
                        input_shape = input_shape[0]

                    input_dim = input_shape[-1] if len(input_shape) > 2 and input_shape[-1] is not None else 775
                    hidden_dim = lstm_layer.units
                    seq_length = input_shape[1] if len(input_shape) > 2 and input_shape[1] is not None else max_length // 2

                    layer_flops = 2 * 4 * (input_dim * hidden_dim + hidden_dim * hidden_dim) * seq_length * batch_size
                    flops += layer_flops
                    print(f"Bidirectional LSTM ({layer.name}): {layer_flops:,} FLOPs")
                    print(f"  - Input dim: {input_dim}, Hidden dim: {hidden_dim}, Seq length: {seq_length}")

            elif isinstance(layer, tf.keras.layers.Embedding):
                # FLOPs for Embedding lookup (relatively small)
                vocab_size = layer.input_dim
                embed_dim = layer.output_dim
                seq_length = max_length

                layer_flops = vocab_size * embed_dim * seq_length * batch_size
                flops += layer_flops
                print(f"Embedding ({layer.name}): {layer_flops:,} FLOPs")
                print(f"  - Vocab size: {vocab_size}, Embed dim: {embed_dim}, Seq length: {seq_length}")

        except Exception as e:
            print(f"Skipping layer {layer.name}: {str(e)}")
            continue

    print("-"*80)
    print(f"Total FLOPs: {flops:,}\n")

    return flops

# Calculate FLOPs - build model first with sample data
print("\nCalculating FLOPs...")
_ = model(X_train_padded[:1])  # Forward pass to ensure model is built

estimated_flops = calculate_flops(model, batch_size=1)  # Per sample FLOPs
metrics.set_flops(estimated_flops)
print(f"Estimated FLOPs per sample: {estimated_flops:,}")
print(f"Estimated FLOPs (GFLOPs): {estimated_flops/1e9:.4f}")

# Record memory usage before training
metrics.record_memory_usage()

# ============================================
# CREATE CHECKPOINT DIRECTORY
# ============================================
import os

checkpoint_dir = 'model_checkpoints'
os.makedirs(checkpoint_dir, exist_ok=True)

best_model_path = os.path.join(checkpoint_dir, 'best_model.h5')
checkpoint_path = os.path.join(checkpoint_dir, 'checkpoint_epoch_{epoch:02d}_val_acc_{val_accuracy:.4f}.h5')

print(f"\n[CHECKPOINT] Checkpoint directory created: {checkpoint_dir}")
print(f"[CHECKPOINT] Best model will be saved to: {best_model_path}")

# ============================================
# TRAINING WITH CHECKPOINT MANAGEMENT
# ============================================

print("\nStarting training with checkpoint management...")
metrics.start_training()

# Define callbacks
checkpoint_callback = ModelCheckpoint(
    filepath=best_model_path,
    monitor='val_accuracy',
    save_best_only=True,
    save_weights_only=False,
    mode='max',
    verbose=1
)

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True,
    verbose=1
)

# Additional checkpoint to save periodic checkpoints
periodic_checkpoint = ModelCheckpoint(
    filepath=checkpoint_path,
    monitor='val_accuracy',
    save_best_only=False,
    save_freq='epoch',
    verbose=0
)

# Train the model with callbacks
history = model.fit(
    X_train_padded, y_train,
    epochs=50,
    batch_size=64,
    validation_data=(X_val_padded, y_val),
    callbacks=[checkpoint_callback, early_stopping],
    verbose=1
)

metrics.end_training()
print(f"\n[METRICS] Training completed in {metrics.get_training_time():.2f} seconds")
print(f"[CHECKPOINT] Best model saved at: {best_model_path}")

# Record memory usage after training
metrics.record_memory_usage()

# ============================================
# LOAD BEST MODEL FOR EVALUATION
# ============================================
print("\n[MODEL] Loading best model checkpoint for evaluation...")

from tensorflow.keras.models import load_model

# Clear session to free memory
tf.keras.backend.clear_session()

# Load the best model with custom objects
best_model = load_model(
    best_model_path,
    custom_objects={
        'scaled_dot_product_attention': scaled_dot_product_attention,
        'attention_output_shape': attention_output_shape,
        'apply_scaled_attention_to_lambda': apply_scaled_attention_to_lambda # Add the new custom function here
    }
)
print("[MODEL] Best model loaded successfully!")

# Verify loaded model
print("\nLoaded Model Summary:")
best_model.summary()

# Record memory after loading model
metrics.record_memory_usage()

# ============================================
# EVALUATION WITH BEST MODEL
# ============================================

print("\n" + "="*80)
print("EVALUATING BEST MODEL ON TEST SET")
print("="*80)

# Evaluate on test set
loss, accuracy = best_model.evaluate(X_test_padded, y_test, verbose=1)
print(f"\nTest Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")

# Store test accuracy in metrics
metrics.set_test_accuracy(accuracy)

# Visualize training history
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# ============================================
# INFERENCE TIME MEASUREMENT
# ============================================

print("\n" + "="*80)
print("MEASURING INFERENCE TIME")
print("="*80)

# Measure inference time for individual samples
num_inference_samples = min(100, len(X_test_padded))
print(f"\nMeasuring inference time on {num_inference_samples} samples...")

for i in range(num_inference_samples):
    sample = X_test_padded[i:i+1]

    start_time = time.time()
    prediction = best_model.predict(sample, verbose=0)
    end_time = time.time()

    inference_time = end_time - start_time
    metrics.record_inference_time(inference_time)

print(f"Average inference time (single): {metrics.get_average_inference_time_ms():.4f} ms per sample")

# Batch inference time
print(f"\nMeasuring batch inference time on {len(X_test_padded)} samples...")
batch_start = time.time()
batch_predictions = best_model.predict(X_test_padded, verbose=0)
batch_end = time.time()
batch_inference_time = batch_end - batch_start
batch_avg_time_ms = (batch_inference_time / len(X_test_padded)) * 1000

print(f"Batch inference time: {batch_inference_time:.4f} seconds for {len(X_test_padded)} samples")
print(f"Batch average per sample: {batch_avg_time_ms:.4f} ms")

# Record memory after inference
metrics.record_memory_usage()

# ============================================
# CLASSIFICATION REPORT AND CONFUSION MATRIX
# ============================================

print("\n" + "="*80)
print("DETAILED PERFORMANCE METRICS")
print("="*80)

# Generate predictions
y_pred = best_model.predict(X_test_padded, verbose=0)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true_classes = np.argmax(y_test, axis=1)

# Classification Report
from sklearn.metrics import classification_report
print("\nClassification Report:")
print(classification_report(y_true_classes, y_pred_classes, target_names=class_labels))

# Confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_true_classes, y_pred_classes)

# Visualize the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.tight_layout()
plt.show()

# ============================================
# COMPREHENSIVE COMPUTATIONAL METRICS SUMMARY
# ============================================

# Record final memory usage
metrics.record_memory_usage()

# Print detailed summary
metrics.print_summary()

# Print paper-ready table
metrics.print_paper_table(batch_inference_time=batch_inference_time, batch_size=len(X_test_padded))

# Export metrics to dictionary
import json
metrics_file = 'computational_metrics.json'
with open(metrics_file, 'w') as f:
    json.dump(metrics.export_to_dict(), f, indent=4)
print(f"\n[METRICS] Computational metrics saved to: {metrics_file}")

# ============================================
# PREDICTION FUNCTION WITH TIMING
# ============================================

def predict_sentiment(sentence, model, vocabulary, max_length, label_encoder):
    # 1. Preprocess the input sentence
    sentence = processText(sentence)
    sentence = remove_hindi_full_stop(sentence)
    sentence_tokens = tokenization(sentence)

    # 2. Convert tokens to numerical sequence
    sequence = []
    for word in sentence_tokens:
        if word in vocabulary:
            sequence.append(vocabulary[word])
        elif word.isdigit():
            sequence.append(vocabulary['digit'])
        else:
            sequence.append(vocabulary['unknown'])

    # 3. Pad the sequence
    padded_sequence = pad_sequences([sequence], maxlen=max_length, padding='post')

    # 4. Make prediction with timing
    start_time = time.time()
    prediction = model.predict(padded_sequence, verbose=0)
    end_time = time.time()

    inference_time = end_time - start_time

    # 5. Convert prediction to class label
    predicted_class = np.argmax(prediction)
    predicted_label = label_encoder.inverse_transform([predicted_class])[0]

    return predicted_label, inference_time

# ============================================
# TEST ON UNSEEN SENTENCES
# ============================================

# Example usage with timing
unseen_sentences = [
    ("Entertainment", "मैंने इस फिल्म को देखा और कहानी बहुत ही अद्भुत और अद्वितीय थी। यह एक शानदार अनुभव था।"),
    ("Product Review", "इस उत्पाद की गुणवत्ता इतनी खराब है कि इसे इस्तेमाल करना मेरे लिए एक कठिनाई बन गया।"),
    ("Weather", "आज सुबह जब मैं बाहर गया तो ठंडी हवा और हल्की बारिश ने पूरे दिन को सुखद बना दिया।"),
    ("Sports", "कल का क्रिकेट मैच बेहद उबाऊ था, कोई रोमांच नहीं था और खेल पूरी तरह से एकतरफा हो गया।"),
    ("Business/Startup", "इस नए स्टार्टअप ने जिस तरह से अपने विचारों को वास्तविकता में बदला है, वह बेहद प्रेरणादायक है।"),
]

print("\n" + "="*80)
print("TESTING ON UNSEEN SENTENCES")
print("="*80)

for field, sentence in unseen_sentences:
    predicted_sentiment, inf_time = predict_sentiment(sentence, best_model, vocabulary, max_length, label_encoder)
    print(f"\nField: {field}")
    print(f"Sentence: {sentence[:80]}...")
    print(f"Predicted Sentiment: {predicted_sentiment}")
    print(f"Inference Time: {inf_time*1000:.4f} ms")
    print("-" * 80)
